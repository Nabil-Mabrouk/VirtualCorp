{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sandbox jupyter notebook is for testing parts of the logic before implementing them inti the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managing openai api key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can set the openai api key as os environment variable but in this case it will need to set it in the .env file\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# print(openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# if you don't already have the open ai api key as environement variabke you can loaded from the .env file\n",
    "# the key will be first searched for in your system. if not found it will look into the .env file\n",
    "# if you set the api key both on your path and in the .env file, the key set in the path will be used)\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### open ai chat models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: 55 models\n",
      "davinci\n",
      "text-davinci-001\n",
      "text-search-curie-query-001\n",
      "gpt-3.5-turbo\n",
      "babbage\n",
      "text-babbage-001\n",
      "curie-instruct-beta\n",
      "text-davinci-003\n",
      "davinci-similarity\n",
      "code-davinci-edit-001\n",
      "text-similarity-curie-001\n",
      "ada-code-search-text\n",
      "gpt-3.5-turbo-0613\n",
      "text-search-ada-query-001\n",
      "gpt-3.5-turbo-16k-0613\n",
      "babbage-search-query\n",
      "ada-similarity\n",
      "text-curie-001\n",
      "gpt-3.5-turbo-16k\n",
      "text-search-ada-doc-001\n",
      "text-search-babbage-query-001\n",
      "code-search-ada-code-001\n",
      "curie-search-document\n",
      "davinci-002\n",
      "text-search-davinci-query-001\n",
      "text-search-curie-doc-001\n",
      "babbage-search-document\n",
      "babbage-002\n",
      "babbage-code-search-text\n",
      "text-embedding-ada-002\n",
      "davinci-instruct-beta\n",
      "davinci-search-query\n",
      "text-similarity-babbage-001\n",
      "text-davinci-002\n",
      "code-search-babbage-text-001\n",
      "text-search-davinci-doc-001\n",
      "code-search-ada-text-001\n",
      "ada-search-query\n",
      "text-similarity-ada-001\n",
      "ada-code-search-code\n",
      "whisper-1\n",
      "text-davinci-edit-001\n",
      "davinci-search-document\n",
      "curie-search-query\n",
      "babbage-similarity\n",
      "ada\n",
      "ada-search-document\n",
      "text-ada-001\n",
      "text-similarity-davinci-001\n",
      "curie-similarity\n",
      "babbage-code-search-code\n",
      "code-search-babbage-code-001\n",
      "text-search-babbage-doc-001\n",
      "gpt-3.5-turbo-0301\n",
      "curie\n"
     ]
    }
   ],
   "source": [
    "# get the list of available models\n",
    "models = openai.Model.list()[\"data\"]\n",
    "print(\"Found:\", len(models), \"models\")\n",
    "for model in models:\n",
    "    print(model[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# example of use\n",
    "chat_completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=[{\"role\": \"user\", \"content\": \"Hello world\"}])\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more sophisticated message\n",
    "message =[{'role':'system', 'content':'The developper instructions goes here'}, \n",
    "          {'role':'assistant', 'content':'Previous answer of the model goes here'}, \n",
    "          {'role':'user', 'content':'The agent or human message goes here'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rules:\n",
      "1. The business idea should be legal.\n",
      "2. The business idea should be related to the sport.\n"
     ]
    }
   ],
   "source": [
    "# Example 1\n",
    "message =[{'role':'system', 'content':'You will be provided with the prompts a virtual agent. From this prompt and only from this prompt you must extract the rules that the agent must comply with.'}, \n",
    "          {'role':'user', 'content':'agent prompt: you have to provide a legal business idea. You business idea should be related to sport '}]\n",
    "\n",
    "chat_completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=message)\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You will be provided with the prompt of a virtual agent. From this prompt and only from this prompt\n",
      " you must extract the rules that the agent must comply with. Don't invent rules that are not mentioned to in the agent's prompt.\n",
      " ------------------------------------\n",
      " Agent prompt: you have to provide a legal business idea. You business idea should be related to sport\n",
      " ------------------------------------\n",
      "Your answer should be according to this format:\n",
      "1. rule-1\n",
      "2. rule_2\n",
      "..\n",
      "\n",
      "1. The business idea must be related to sport.\n",
      "2. The business idea must be legal.\n"
     ]
    }
   ],
   "source": [
    "input_dict={\"input\":\"you have to provide a legal business idea. You business idea should be related to sport\"}\n",
    "prompt=\"\"\"You will be provided with the prompt of a virtual agent. From this prompt and only from this prompt\n",
    " you must extract the rules that the agent must comply with. Don't invent rules that are not mentioned to in the agent's prompt.\n",
    " ------------------------------------\n",
    " Agent prompt: <INPUT>\n",
    " ------------------------------------\n",
    "Your answer should be according to this format:\n",
    "1. rule-1\n",
    "2. rule_2\n",
    "..\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "for key, value in input_dict.items():\n",
    "    placeholder = f\"<{key.upper()}>\"\n",
    "    prompt = prompt.replace(placeholder, value)\n",
    "\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "\n",
    "response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        temperature=0.7,\n",
    "        max_tokens=2000,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "\n",
    "print(response.choices[0].text.strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
